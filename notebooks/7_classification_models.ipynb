{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models\n",
    "\n",
    "We develop classification models to predict whether the murder rate in each metropolitan area will be above 8.5 (the historical 90th percentile rate) in subsequent years. We choose to develop the binary categorical prediction model like this one, because we believe they will produce results that can be more useful to policy makers than continuous analysis alone. Policy makers in violent areas are interested in understanding the factors that make their area violent, so that they can develop policies that will reduce levels of violence among their constituency. For this reason, we developed a classification algorithm that can predict if an area will be unusually violent, so that the factors that lead to unusual violence can be isolated and addressed by policy makers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "import seaborn.apionly as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import export_graphviz\n",
    "pd.options.mode.chained_assignment = None   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3893, 303)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned data/merged_dataset.csv').drop('Unnamed: 0', axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3893, 317)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create some vars\n",
    "def makelog(dframe, varname, varname2, orig_var):\n",
    "    dframe[varname] = np.log(dframe[orig_var])\n",
    "    dframe[varname2] = (np.log(dframe[orig_var]))**2\n",
    "    \n",
    "    \n",
    "makelog(df, 'log_pop', 'log_pop2', 'pop')\n",
    "makelog(df, 'log_mean_inc_white', 'log_mean_inc_white2', 'mean_inc_white')\n",
    "makelog(df, 'log_mean_inc_black', 'log_mean_inc_black2', 'mean_inc_black')\n",
    "makelog(df, 'log_mean_inc_hispanic', 'log_mean_inc_hispanic2', 'mean_inc_hispanic')\n",
    "\n",
    "\n",
    "df['poor_nonwhite']=df['poor']-df['poor_white']\n",
    "df['LA'] = df['state'] == 'Louisiana' \n",
    "df['AK'] = df['state'] == 'Arkansas'\n",
    "df['MI'] = df['state'] == 'Mississippi'\n",
    "df['SC'] = df['state'] == 'South Carolina'\n",
    "df['OK'] = df['state'] == 'Oklahoma'\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split into training and test datasets \n",
    "np.random.seed(1818)\n",
    "msk = np.random.rand(len(df)) < 0.66\n",
    "dftrain = df[msk]\n",
    "dftest = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set the predictors we will use \n",
    "df_gun_laws=pd.read_csv('raw data/state-firearms/raw_data.csv')\n",
    "#gun_vars = list(df_gun_laws)[2:]\n",
    "gun_vars = ['age21longgunpossess', 'ccbackgroundnics', 'ccrevoke', 'dealerh', 'drugmisdemeanor', 'incidentremoval',\n",
    "            'lockd', 'loststolen', 'onepermonth', 'opencarryh', 'opencarrypermith', 'permitconcealed', 'personalized',\n",
    "            'recordsallh', 'stalking']\n",
    "\n",
    "#census vars\n",
    "cen_vars1=['pct_hispanic', 'pct_white', 'pct_black', 'pct_indian', 'pct_asian', 'pct_hawaiian', \n",
    "           'pct_other', 'pct_mixed', 'pct_foreign_citizen']\n",
    "cen_vars2 = ['log_pop', 'log_pop2', 'pop5_14', 'pop15_17', 'pop18_24', 'pop15_44', 'pop65up', \n",
    "             'median_age', 'sex_ratio',  'age_dep', 'oldage_dep', 'child_dep']\n",
    "cen_vars3 = ['families_singledad', 'families_singlemom', 'family_size',  'pct_ownhouse']\n",
    "cen_vars4 = ['pct15up_married', 'pct15up_widowed', 'pct15up_divorced', 'pct15up_separated', \n",
    "             'pct15up_nevermar']\n",
    "cen_vars5 = ['pct_enroll_public', 'pct_enroll_private', 'pct15_17_enroll', 'pct18_19_enroll', \n",
    "             'pct18_24_lesshs', 'pct18_24_hs', 'pct18_24_somecol']\n",
    "cen_vars6 = ['pct25up_less9','pct25up_nohs', 'pct25up_hs', 'pct25up_somecol', 'pct25up_somecol2', \n",
    "             'pct25up_col', 'pct25up_grad']\n",
    "cen_vars7 = ['poor', 'poor_nonwhite', 'fam_cash_assist', 'fam_social_sec', 'log_mean_inc_white', \n",
    "             'log_mean_inc_white2','log_mean_inc_black', 'log_mean_inc_black2','income10lo', 'income10_15', \n",
    "             'income15_25', 'income25_35', 'income35_50', 'income50_75', 'income75_100', 'income100_150', \n",
    "             'income150_200', 'income200up']\n",
    "cen_vars8 = ['pct18_veterans', 'pct_disabled20_64', 'employed20_64', 'unemployed20_64', 'employed_white', \n",
    "             'unemployed_white', 'employed20_64_m', 'unemployed20_64_m', 'employed20_64_f', 'unemployed20_64_f']\n",
    "cen_vars9 = ['pct16_manuf', 'pct16_info', 'pct16_finance', 'pct16_prof', 'pct16_edhealth', 'LA', 'AK', 'MI', 'SC','OK']\n",
    "cen_vars = cen_vars1 + cen_vars2 + cen_vars3 +cen_vars4 +cen_vars5+ cen_vars6 +cen_vars7 + cen_vars8 + cen_vars9\n",
    "\n",
    "#all predictors\n",
    "predictors = gun_vars + cen_vars\n",
    "\n",
    "#set outcomes\n",
    "outcomes=['Total', 'Estimated', 'Rate']\n",
    "\n",
    "#all vars of interest\n",
    "var_needed= predictors+outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2610, 100) (1283, 100)\n"
     ]
    }
   ],
   "source": [
    "#limit datasets to just subset of vars\n",
    "dftrain=dftrain[var_needed]\n",
    "dftest=dftest[var_needed]\n",
    "print(dftrain.shape, dftest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9    8.5\n",
       "Name: Rate, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification variable: 90 percentile murder rate in the training data\n",
    "dftrain['Rate'].quantile([.90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dummy = 1 if rate > cutoff (8.5)\n",
    "dftrain['High'] = (dftrain['Rate'] >= 8.5).astype(int) \n",
    "dftest['High'] = (dftest['Rate'] >= 8.5).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1283.000000\n",
       "mean        0.102884\n",
       "std         0.303926\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000\n",
       "Name: High, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest['High'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = dftrain[dftrain.columns[:-4]]\n",
    "ytrain = dftrain['High']\n",
    "\n",
    "xtest = dftest[dftest.columns[:-4]]\n",
    "ytest = dftest['High']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first look at logistic models, kNN, LDA, and QDA to predict whether an MSA will have a high murder rate. Given that only about 10% of the training dataset has a murder rate higher than 8.5, we give class=1 greater weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = lambda model, x_train, y_train: pd.Series([model.score(x_train, y_train), \n",
    "                                                 model.score(x_train[y_train==0], y_train[y_train==0]),\n",
    "                                                 model.score(x_train[y_train==1], y_train[y_train==1])], \n",
    "                                                index=['overall accuracy', 'accuracy on class 0', 'accuracy on class 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unweighted Logistic model\n",
    "cvals = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100, 10000, 100000]\n",
    "Ulm = LogisticRegressionCV(Cs=cvals, cv=10)\n",
    "Ulm = Ulm.fit(xtrain, ytrain)\n",
    "\n",
    "Ulm_scores = score(Ulm, xtrain, ytrain)\n",
    "Ulm_scores_test = score(Ulm, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Weighted Logistic model\n",
    "lm = LogisticRegressionCV(Cs=cvals, cv=10, class_weight='balanced')\n",
    "lm = lm.fit(xtrain, ytrain)\n",
    "\n",
    "lm_scores = score(lm, xtrain, ytrain)\n",
    "lm_scores_test = score(lm, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kNN\n",
    "klist = [2, 5, 10, 20, 40, 50]\n",
    "xval_scores = []\n",
    "\n",
    "for k in klist:\n",
    "    KNN = KNeighborsClassifier(n_neighbors=k)\n",
    "    xval_scores.append(np.mean(cross_val_score(KNN, xtrain, ytrain, cv=10)))\n",
    "    \n",
    "imax = xval_scores.index(np.max(xval_scores))\n",
    "kval = klist[imax]\n",
    "\n",
    "#fit model\n",
    "KNN = KNeighborsClassifier(n_neighbors=kval)\n",
    "KNN.fit(xtrain, ytrain)\n",
    "\n",
    "knn_scores = score(KNN, xtrain, ytrain)\n",
    "knn_scores_test = score(KNN, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "LDA.fit(xtrain, ytrain)\n",
    "\n",
    "LDA_scores = score(LDA, xtrain, ytrain)\n",
    "LDA_scores_test = score(LDA, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "#QDA\n",
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "QDA.fit(xtrain, ytrain)\n",
    "\n",
    "QDA_scores = score(QDA, xtrain, ytrain)\n",
    "QDA_scores_test = score(QDA, xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree & Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next explore single decision tree, Random Forest, gradient boosting and SVC. For the random forest model, we use cross validation to determine the optimal number of trees and the optimal number of predictors for splitting. For the gradient boosting method, we also use cross validation to choose optimal number of trees and and tree depth for the base learner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Single Decision Tree\n",
    "xval_scores = []\n",
    "depths = list(range(2, 11))\n",
    "\n",
    "for d in depths:\n",
    "    dt = DecisionTreeClassifier(max_depth = d, criterion='gini')\n",
    "    xval_scores.append(np.mean(cross_val_score(dt, xtrain, ytrain, cv=5)))\n",
    "    \n",
    "imax = xval_scores.index(np.max(xval_scores))\n",
    "opt_depth = depths[imax]\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth = opt_depth, criterion='gini', class_weight='balanced')\n",
    "dt.fit(xtrain, ytrain)\n",
    "tree_scores = score(dt, xtrain, ytrain)\n",
    "tree_scores_test = score(dt, xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the optimal number of trees\n",
    "trees, train_score, test_score = [], [], []\n",
    "\n",
    "for x in range(8):\n",
    "    rf = RandomForestClassifier(n_estimators=2**(x+1), max_features='auto', class_weight='balanced')\n",
    "    rf_fitted = rf.fit(xtrain, ytrain)\n",
    "    trees.append(2**(x+1))\n",
    "    train_score.append(rf_fitted.score(xtrain, ytrain))\n",
    "    test_score.append(rf_fitted.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trees</th>\n",
       "      <th>Training score</th>\n",
       "      <th>Test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.949425</td>\n",
       "      <td>0.903352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.969732</td>\n",
       "      <td>0.908028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.975862</td>\n",
       "      <td>0.901013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.981609</td>\n",
       "      <td>0.907249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0.986973</td>\n",
       "      <td>0.911925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>0.989272</td>\n",
       "      <td>0.908807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>128</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.908807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>0.989655</td>\n",
       "      <td>0.908028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trees  Training score  Test score\n",
       "0      2        0.949425    0.903352\n",
       "1      4        0.969732    0.908028\n",
       "2      8        0.975862    0.901013\n",
       "3     16        0.981609    0.907249\n",
       "4     32        0.986973    0.911925\n",
       "5     64        0.989272    0.908807\n",
       "6    128        0.988889    0.908807\n",
       "7    256        0.989655    0.908028"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfdf = pd.DataFrame({'Trees': trees, 'Training score': train_score, 'Test score': test_score})\n",
    "rfdf = rfdf[['Trees', 'Training score', 'Test score' ]]\n",
    "rfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the optimal number of predictors for splitting\n",
    "param_grid = dict(num_pred = list(range(1, xtrain.shape[1])))\n",
    "results = {}\n",
    "estimators= {}\n",
    "\n",
    "for f in param_grid['num_pred']:\n",
    "    est = RandomForestClassifier(oob_score=True, class_weight='balanced', n_estimators=32, \n",
    "                                 max_features=f, max_depth=opt_depth, n_jobs=-1)\n",
    "    est.fit(xtrain, ytrain)\n",
    "    results[f] = est.oob_score_\n",
    "    estimators[f] = est\n",
    "opt_pred = max(results, key = results.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(oob_score=True, n_estimators=32, class_weight='balanced',\n",
    "                            max_features=opt_pred, max_depth=opt_depth, n_jobs=-1)\n",
    "rf_fitted = rf.fit(xtrain, ytrain)\n",
    "\n",
    "RF2_scores = score(rf_fitted, xtrain, ytrain)\n",
    "RF2_scores_test = score(rf_fitted, xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracies_train = []\n",
    "accuracies_test = []\n",
    "for md in [1,2,]:\n",
    "    depth_accuracies_train = []\n",
    "    depth_accuracies_test = []\n",
    "    ada=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=opt_depth),n_estimators=trees[-1], learning_rate=.05)\n",
    "    ada.fit(xtrain,ytrain)\n",
    "    ada_train_gen = ada.staged_predict(xtrain)\n",
    "    ada_test_gen = ada.staged_predict(xtest)\n",
    "    for train_stagepred in ada_train_gen:    \n",
    "        depth_accuracies_train.append(metrics.accuracy_score(ytrain, train_stagepred))\n",
    "    for test_stagepred in ada_test_gen:   \n",
    "        depth_accuracies_test.append(metrics.accuracy_score(ytest, test_stagepred))\n",
    "    accuracies_train.append(depth_accuracies_train)\n",
    "    accuracies_test.append(depth_accuracies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "          learning_rate=0.05, n_estimators=300, random_state=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the optimal number of trees and the optimal tree depth for the base learner\n",
    "param_grid_boost = {\n",
    "              'base_estimator__max_depth': list(range(1,11))\n",
    "}\n",
    "gb = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=300, learning_rate=.05)\n",
    "gb_cv = GridSearchCV(gb, param_grid_boost, cv=5, n_jobs=-1)\n",
    "\n",
    "gb_cv.fit(xtrain, ytrain)\n",
    "\n",
    "begb = gb_cv.best_estimator_\n",
    "begb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal # trees =  149\n",
      "Optimal depth =  1\n"
     ]
    }
   ],
   "source": [
    "test_scores=[]\n",
    "for spred in begb.staged_predict(xtest):\n",
    "    test_scores.append(metrics.accuracy_score(spred, ytest))\n",
    "    \n",
    "print (\"Optimal # trees = \", range(1, 301)[np.argmax(test_scores)])\n",
    "print (\"Optimal depth = \", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_optimized = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), \n",
    "                                  n_estimators=149, learning_rate=.05)\n",
    "\n",
    "gb_optimized.fit(xtrain, ytrain).score(xtest, ytest)\n",
    "\n",
    "boost_scores = score(gb_optimized, xtrain, ytrain)\n",
    "boost_scores_test = score(gb_optimized, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC \n",
    "SVC = SVC(C=100, class_weight='balanced')\n",
    "SVC.fit(xtrain, ytrain)\n",
    "SVC_scores = score(SVC, xtrain, ytrain)\n",
    "SVC_scores_test = score(SVC, xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Boosting</th>\n",
       "      <th>LDA</th>\n",
       "      <th>QDA</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>SVC</th>\n",
       "      <th>Tree</th>\n",
       "      <th>Unweighted Logistic</th>\n",
       "      <th>Weighted Logistic</th>\n",
       "      <th>kNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall accuracy</th>\n",
       "      <td>0.909962</td>\n",
       "      <td>0.919157</td>\n",
       "      <td>0.671648</td>\n",
       "      <td>0.860920</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.852490</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.896935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 0</th>\n",
       "      <td>0.991029</td>\n",
       "      <td>0.962409</td>\n",
       "      <td>0.633917</td>\n",
       "      <td>0.864588</td>\n",
       "      <td>0.987612</td>\n",
       "      <td>0.858607</td>\n",
       "      <td>0.987185</td>\n",
       "      <td>0.793251</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 1</th>\n",
       "      <td>0.204461</td>\n",
       "      <td>0.542751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.828996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.799257</td>\n",
       "      <td>0.275093</td>\n",
       "      <td>0.791822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Boosting       LDA       QDA  Random Forest       SVC  \\\n",
       "overall accuracy     0.909962  0.919157  0.671648       0.860920  0.988889   \n",
       "accuracy on class 0  0.991029  0.962409  0.633917       0.864588  0.987612   \n",
       "accuracy on class 1  0.204461  0.542751  1.000000       0.828996  1.000000   \n",
       "\n",
       "                         Tree  Unweighted Logistic  Weighted Logistic  \\\n",
       "overall accuracy     0.852490             0.913793           0.793103   \n",
       "accuracy on class 0  0.858607             0.987185           0.793251   \n",
       "accuracy on class 1  0.799257             0.275093           0.791822   \n",
       "\n",
       "                          kNN  \n",
       "overall accuracy     0.896935  \n",
       "accuracy on class 0  1.000000  \n",
       "accuracy on class 1  0.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame({'kNN': knn_scores, 'Weighted Logistic': lm_scores,'Unweighted Logistic': Ulm_scores,\n",
    "                         'LDA': LDA_scores,'QDA': QDA_scores, 'Tree': tree_scores, 'Random Forest': RF2_scores,\n",
    "                         'SVC': SVC_scores, 'Boosting': boost_scores})\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Boosting</th>\n",
       "      <th>LDA</th>\n",
       "      <th>QDA</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>SVC</th>\n",
       "      <th>Tree</th>\n",
       "      <th>Unweighted Logistic</th>\n",
       "      <th>Weighted Logistic</th>\n",
       "      <th>kNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall accuracy</th>\n",
       "      <td>0.909587</td>\n",
       "      <td>0.904131</td>\n",
       "      <td>0.656274</td>\n",
       "      <td>0.849571</td>\n",
       "      <td>0.890101</td>\n",
       "      <td>0.831645</td>\n",
       "      <td>0.910366</td>\n",
       "      <td>0.795791</td>\n",
       "      <td>0.897116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 0</th>\n",
       "      <td>0.990443</td>\n",
       "      <td>0.960904</td>\n",
       "      <td>0.629018</td>\n",
       "      <td>0.865334</td>\n",
       "      <td>0.987837</td>\n",
       "      <td>0.849696</td>\n",
       "      <td>0.982624</td>\n",
       "      <td>0.800174</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 1</th>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.674242</td>\n",
       "      <td>0.280303</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Boosting       LDA       QDA  Random Forest       SVC  \\\n",
       "overall accuracy     0.909587  0.904131  0.656274       0.849571  0.890101   \n",
       "accuracy on class 0  0.990443  0.960904  0.629018       0.865334  0.987837   \n",
       "accuracy on class 1  0.204545  0.409091  0.893939       0.712121  0.037879   \n",
       "\n",
       "                         Tree  Unweighted Logistic  Weighted Logistic  \\\n",
       "overall accuracy     0.831645             0.910366           0.795791   \n",
       "accuracy on class 0  0.849696             0.982624           0.800174   \n",
       "accuracy on class 1  0.674242             0.280303           0.757576   \n",
       "\n",
       "                          kNN  \n",
       "overall accuracy     0.897116  \n",
       "accuracy on class 0  1.000000  \n",
       "accuracy on class 1  0.000000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame({'kNN': knn_scores_test, 'Weighted Logistic': lm_scores_test,'Unweighted Logistic': Ulm_scores_test,\n",
    "                         'LDA': LDA_scores_test,'QDA': QDA_scores_test, 'Tree': tree_scores_test, 'Random Forest': RF2_scores_test,\n",
    "                         'SVC': SVC_scores_test, 'Boosting': boost_scores_test})\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in predicting unusually high murder rates, we are most interested in classification accuracy on class 1 rather than overall accuracy. QDA and SVC predict high murder rates with perfect accuracy in the training data, while Random Forest performs next-best, with an accuracy score for class 1 of 0.83. Weighted logistic regression and single decision tree methods perform similarly, producing an accuracy score of about 0.80. In the test set, QDA and and weighted logistic regression have the highest accuracy scores on class 1, with Random forest coming in third with an accuracy of 0.71. It is likely that the SVC model was overfitted, given its low test score. \n",
    "\n",
    "Although the QDA model produces the highest test scores, we choose the weighted logistic regression as our model of choice because the QDA model generates warning of collinearity in our predictors. Although we used a correlation matrix and a stepwise method to determine which variables are collinear, we were not able to determine which variables were causing the issue. Since QDA does not have a penalty function built in like some of the other models, it is likely that our model is not reliable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Logistic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which variables are significant? As mentioned, we are interested in knowing which predictors are important for determining high murder rates. Thus, we look at which variables are significant in our preferred model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain_c = sm.add_constant(xtrain)\n",
    "xtest_c = sm.add_constant(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "\n",
    "B_boot = np.zeros((xtrain_c.shape[1],100))\n",
    "\n",
    "for i in range(iterations):\n",
    "    #sample with replacement from X_train\n",
    "    boot_rows = np.random.choice(range(xtrain_c.shape[0]), size=xtrain_c.shape[0], replace=True)\n",
    "    X_train_boot = xtrain_c.values[boot_rows]\n",
    "    y_train_boot = ytrain.values[boot_rows]\n",
    "\n",
    "    #fit\n",
    "    lm_boot = LogisticRegression(C=10000, class_weight='balanced',fit_intercept=False)\n",
    "    lm_boot.fit(X_train_boot, y_train_boot)\n",
    "    B_boot[:,i] = lm_boot.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B_ci_upper = np.percentile(B_boot, 97.5, axis=1)\n",
    "B_ci_lower = np.percentile(B_boot, 2.5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model: features significant at 5% level\n",
      "age21longgunpossess\n",
      "dealerh\n",
      "drugmisdemeanor\n",
      "lockd\n",
      "permitconcealed\n",
      "personalized\n",
      "log_pop2\n",
      "sex_ratio\n",
      "pct15up_widowed\n",
      "pct15up_separated\n",
      "pct25up_nohs\n",
      "pct_disabled20_64\n",
      "pct16_manuf\n",
      "pct16_prof\n",
      "LA\n",
      "MI\n"
     ]
    }
   ],
   "source": [
    "sig_i = []\n",
    "print (\"Logistic regression model: features significant at 5% level\")\n",
    "\n",
    "#if ci contains 0, then insignificant\n",
    "for i in range(xtrain_c.shape[1]):\n",
    "    if B_ci_upper[i]<0 or B_ci_lower[i]>0:\n",
    "        sig_i.append(i)\n",
    "\n",
    "#print significant predictors\n",
    "for i in sig_i:\n",
    "    print(xtrain_c.columns[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model predicts that the following variables are important for determining high murder rates:\n",
    "- Laws preventing possession of long guns until age 21\n",
    "- Laws stipulating that state dealer licenses are required for sale of handguns\n",
    "- Laws preventing firearm possession for people with a drug misdemeanor conviction\n",
    "- Laws requiring a safety lock for handguns sold through licensed dealers\n",
    "- Laws requiring a permit to carry concealed weapons\n",
    "- Laws requiring review of personalized gun technology\n",
    "- Log popuation \n",
    "- Sex ratio\n",
    "- Percent of the population age 15 and up who are widowed\n",
    "- Percent of the population age 15 and up who are separated\n",
    "- Percent of the population age 25 and up who have completed less than high school\n",
    "- Percent of the population age 20-64 who are disabled\n",
    "- Percent of the population age 16 and up who work in the manufacturing sector\n",
    "- Percent of the population age 16 and up who work in the professional, science, technology sector\n",
    "- Residence in Louisiana\n",
    "- Residence in Mississippi\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
